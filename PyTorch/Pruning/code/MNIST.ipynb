{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dfbf811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv2d, Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7913263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, activationCNN, activationOut):\n",
    "        super(CNN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # in_channels=1 bo obraz jest jednokanałowy(greyscale)\n",
    "        self.conv1 = Conv2d(1, hidden_channels, kernel_size=3, padding=1) # kernel 3x3, padding=1 pixel czyli output ma ten sam size czyli 28x28\n",
    "        self.conv2 = Conv2d(hidden_channels, hidden_channels * 2, kernel_size=3, padding=1)\n",
    "        self.fullyConnected = Linear(hidden_channels * 2 * 7 * 7, 10) # (hidden channels * 2 * 2) to  wyjscie z warstwy 2 konwolucyjnej a 7x7 to dlatego ze poczatkowy rozmiar obrazka jest 28x28\n",
    "        # alepo każdej warstwie konwolucyjnej był pooling 2x2, który redukuje wektor wejściowy, czyli 28:(2x2) = 7\n",
    "        self.activationCNN = activationCNN\n",
    "        self.activationOut = activationOut\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activationCNN(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.activationCNN(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if self.activationOut == torch.softmax:\n",
    "            x = self.activationOut(self.fullyConnected(x), dim=1)\n",
    "        else:\n",
    "            x = self.activationOut(self.fullyConnected(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d50afdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(hidden_channels=64, activationCNN=F.leaky_relu, activationOut=torch.sigmoid)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20fcb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the weights of each layer\n",
    "conv1_weights = model.conv1.weight.clone()\n",
    "conv2_weights = model.conv2.weight.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058f74f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "          [ 0.3062, -0.0730,  0.0673],\n",
       "          [-0.1623,  0.1958,  0.2938]]],\n",
       "\n",
       "\n",
       "        [[[-0.2445,  0.2897,  0.0624],\n",
       "          [ 0.2463,  0.0451,  0.1607],\n",
       "          [-0.0471,  0.2570,  0.0493]]],\n",
       "\n",
       "\n",
       "        [[[-0.1556,  0.0850, -0.1536],\n",
       "          [-0.0391, -0.1354,  0.2211],\n",
       "          [-0.2631, -0.1537, -0.0941]]],\n",
       "\n",
       "\n",
       "        [[[-0.2004,  0.0315, -0.3292],\n",
       "          [ 0.3010, -0.2832,  0.2573],\n",
       "          [ 0.0555, -0.1082,  0.2060]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0520,  0.2693,  0.0364],\n",
       "          [-0.1051,  0.0896, -0.0904],\n",
       "          [ 0.1403,  0.2976,  0.1927]]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_weights[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "369d4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a94b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    inputs = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            predictions.append(pred)\n",
    "            targets.append(target)\n",
    "            inputs.append(data)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print(correct)\n",
    "    print(len(test_loader.dataset))\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return accuracy, predictions, targets, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8a29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funckja do trenowania modelu przez zadaną liczbę epok\n",
    "def final_train(epochs, model):\n",
    "    losses = []\n",
    "    for epoch in range(0, epochs):\n",
    "        loss = train(model)\n",
    "        losses.append(loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec57a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST('./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST('./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8f2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce28a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a78b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9884\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a0994c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3455,  0.3502, -0.1280],\n",
       "         [ 0.3648,  0.0399,  0.1467],\n",
       "         [-0.1729,  0.2789,  0.4004]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2098c311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2548,  0.2767, -0.0781],\n",
       "         [ 0.3062, -0.0730,  0.0673],\n",
       "         [-0.1623,  0.1958,  0.2938]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33b8f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weights_after_training = model.conv1.weight\n",
    "conv2_weights_after_training = model.conv2.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22f8d6",
   "metadata": {},
   "source": [
    "<font size=\"5\">Można sobie powyswietlac wagi. Zwrócić uwagę, że named buffor jest pusty - po pruningu będzie tam maska pruningu.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea220b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.conv1.named_parameters())) # nie wiem jeszcze czym sie roznia named_parameters od wag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76caadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.conv1.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa086a8",
   "metadata": {},
   "source": [
    "<font size=\"5\">Pruning wag konwolucyjnych. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33bf92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf7fc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff1312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.2,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a80718a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc101a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9897\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6736b",
   "metadata": {},
   "source": [
    "<font size=\"5\">Wyswietlamy wagi itp, należy zwrócić uwagę, że named buffor się wypełnił maską 0 i 1. Po wywołaniu funkcji prune.remove wagi z maską=0 ustawiane są na 0.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebff0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = model.conv1\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39230ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5981220",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.l1_unstructured(module, name=\"bias\", amount=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660cab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92416f75",
   "metadata": {},
   "source": [
    "<font size=\"5\">W wektorze weights waga, która po pruningu w named bufforze ma flagę 0 odrazu jest ustawiona na 0 natomiast w named_params dopiero po prune.remove.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c2b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf12a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.remove(model.conv2, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749843dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1f346",
   "metadata": {},
   "source": [
    "<font size=\"5\">Ile procent usunietych wag</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e31749",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sparsity in fc2.weight: {:.2f}%\".format(100. * float(torch.sum(model.conv1.weight == 0))/ float(model.conv1.weight.nelement())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b08731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sparsity in fc2.weight: {:.2f}%\".format(100. * float(torch.sum(model.conv2.weight == 0))/ float(model.conv2.weight.nelement())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "092ee210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 20.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3ca61",
   "metadata": {},
   "source": [
    "<font size=\"5\">Pomysł na zrobienie lottery ticketa: <br>\n",
    "- wytrenować model <br>\n",
    "- zrobić pruning <br>\n",
    "- przywrócić wagi <br>\n",
    "- wywołać metodę prune.remove <br>\n",
    "Jesli to nie zadziała to rzemieślniczo metoda, jechać element po elemencie po wadze i tam gdzie 0 w named bufforze albo w skopiowanym wektorze wag, tam ustawic 0.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "965ffef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.4,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c8c94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a53e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9904\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84cb1adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 52.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76a183e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.6,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2264d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5faf97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9da8ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 80.80%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.6,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c29b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30528eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce971d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.8,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ebbf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61ce5710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9888\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c628ced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 96.16%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.remove(model.conv1, 'weight')\n",
    "prune.remove(model.conv2, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfaca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7efc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b5f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff80dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.9996,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2a78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 99.96%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf5a40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "587fd80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2720838",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.9996,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed9c12af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b00595",
   "metadata": {},
   "source": [
    "<font size=\"5\">Winning tickety</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd7b18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75c0a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29513066",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.2,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "562474ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 20.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088834f",
   "metadata": {},
   "source": [
    "<font size=\"3\">Przepisanie wag</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51138105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3455,  0.3502, -0.1280],\n",
       "         [ 0.3648,  0.0399,  0.1467],\n",
       "         [-0.1729,  0.2789,  0.4004]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5524745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2548,  0.2767, -0.0781],\n",
       "         [ 0.3062, -0.0730,  0.0673],\n",
       "         [-0.1623,  0.1958,  0.2938]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a0c6ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3455,  0.3502, -0.1280], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "587ddc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3455, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae5eedee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3455, grad_fn=<UnbindBackward0>)\n",
      "tensor(0.3502, grad_fn=<UnbindBackward0>)\n",
      "tensor(-0.1280, grad_fn=<UnbindBackward0>)\n",
      "tensor(0.3648, grad_fn=<UnbindBackward0>)\n",
      "tensor(0.0399, grad_fn=<UnbindBackward0>)\n",
      "tensor(0.1467, grad_fn=<UnbindBackward0>)\n",
      "tensor(-0.1729, grad_fn=<UnbindBackward0>)\n",
      "tensor(0.2789, grad_fn=<UnbindBackward0>)\n",
      "tensor(0.4004, grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for row in model.conv1.weight[0][0]:\n",
    "    for weight in row:\n",
    "        print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ee623a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c56d241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.conv1.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3899ebb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.conv1.weight[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6f83151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverOriginalWeightsW1():\n",
    "    clone = model.conv1.weight.clone()\n",
    "    for i, neuron in enumerate(model.conv1.weight):\n",
    "        for j, row in enumerate(neuron[0]) :\n",
    "            for k, weight in enumerate(row):\n",
    "#                 print(clone[i][0][j][k])\n",
    "#                 print(conv1_weights[i][0][j][k])\n",
    "                if weight != 0: # pomijamy sprunowane wagi\n",
    "                    clone[i][0][j][k].fill_(conv1_weights[i][0][j][k].detach())\n",
    "    return clone                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "782169eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printW(tensor):\n",
    "    for i, neuron in enumerate(tensor):\n",
    "        for j, row in enumerate(neuron[0]) :\n",
    "            for k, weight in enumerate(row):\n",
    "                print(tensor[i][0][j][k])\n",
    "                print(conv1_weights[i][0][j][k])\n",
    "                print(model.conv1.weight[i][0][j][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0176ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = recoverOriginalWeightsW1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a80ccacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight = clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c90b81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverOriginalWeights(original_tensor, replace_tensor):\n",
    "    clone = original_tensor.clone()\n",
    "    for i, neuron in enumerate(original_tensor):\n",
    "        for j, row in enumerate(neuron[0]) :\n",
    "            for k, weight in enumerate(row):\n",
    "                if weight != 0: # pomijamy sprunowane wagi\n",
    "                    clone[i][0][j][k].fill_(replace_tensor[i][0][j][k].detach())\n",
    "    return clone                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "923e35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printW(tensor):\n",
    "    for i, neuron in enumerate(tensor):\n",
    "        for j, row in enumerate(neuron[0]) :\n",
    "            for k, weight in enumerate(row):\n",
    "                print(tensor[i][0][j][k])\n",
    "                print(conv2_weights[i][0][j][k])\n",
    "                print(model.conv2.weight[i][0][j][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1649005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = recoverOriginalWeights(model.conv2.weight, conv2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bfeea064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv2.weight = clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73425374",
   "metadata": {},
   "outputs": [],
   "source": [
    "printW(clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d580e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "07334651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9889\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "09ea5588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 20.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "339ce184",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "421d8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.2,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a206765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 48.80%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2ded21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = recoverOriginalWeightsW1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a5cc9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight = clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3f84dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = recoverOriginalWeights(model.conv2.weight, conv2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "aa045352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv2.weight = clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e7c6d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1611d8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9896\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "da7768f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9e2f399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.6,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9d65bb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 79.52%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = recoverOriginalWeightsW1()\n",
    "model.conv1.weight = clone\n",
    "clone = recoverOriginalWeights(model.conv2.weight, conv2_weights)\n",
    "model.conv2.weight = clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "10c7fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3ef39aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9905\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f4fcc190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 79.52%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6c28b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "63ef8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.8,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fa0019f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 95.90%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8a68d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = recoverOriginalWeightsW1()\n",
    "model.conv1.weight = clone\n",
    "clone = recoverOriginalWeights(model.conv2.weight, conv2_weights)\n",
    "model.conv2.weight = clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eeb55a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fefab688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9883\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8afc3e0",
   "metadata": {},
   "source": [
    "<font size=\"5\">Reinicjalizacja wag</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5167227",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1d2b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9884\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a9dfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd3e89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bedda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.2,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2fe05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomReinitalizeW1(original_tensor):\n",
    "    clone = original_tensor.clone()\n",
    "    for i, neuron in enumerate(original_tensor):\n",
    "        for j, row in enumerate(neuron[0]) :\n",
    "            for k, weight in enumerate(row):\n",
    "                if weight != 0: # pomijamy sprunowane wagi\n",
    "                #if no specific weight initialization method is specified, the weights are initialized using a uniform distribution within the range (-0.1, 0.1)\n",
    "                    tensor = torch.empty(1)\n",
    "                    tensor.uniform_(-0.1, 0.1)\n",
    "                    clone[i][0][j][k].fill_(tensor.item())\n",
    "    return clone                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d096b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight = randomReinitalizeW1(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "840f6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv2.weight = randomReinitalizeW1(model.conv2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f32128b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80436524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9895\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aef267a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35461be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.4,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7319c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 52.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "431ea200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight = randomReinitalizeW1(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ed3561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv2.weight = randomReinitalizeW1(model.conv2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d70b90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2255922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9898\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42dd8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "746c28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.6,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "127c1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight = randomReinitalizeW1(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3314c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv2.weight = randomReinitalizeW1(model.conv2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00903d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36215b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9903\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d12b430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65a6aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.8,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f32531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight = randomReinitalizeW1(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4639717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv2.weight = randomReinitalizeW1(model.conv2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84b4bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d83e66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9888\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35efc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),  # Prune the weights of layer1\n",
    "    (model.conv2, 'weight'),  # Prune the weights of layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed4b75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,  # Use L1-norm based pruning\n",
    "    amount=0.99,  # Prune 20% of the parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd3c2f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 99.96%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b31c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight = randomReinitalizeW1(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b326dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv2.weight = randomReinitalizeW1(model.conv2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71fb47a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = final_train(10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8fdebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4238\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "acc, predictions, targets, inputs = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673f4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
